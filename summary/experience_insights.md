# Experience and Insights
Before discussing my experience and the insights I gained after completing these assignments, I would like to briefly describe my learning journey and how I approached these tasks. I happened to meet Ms. Sherry in the Science Major Week, I was very impressed by her energy and I wanted to join her lab. So that, I started to search Computational Chemistry through the AI4PhysSci Lab website, and I began to look for courses on Computational Chemistry, Machine Learning, Python coding, Statistics on Youtube and Udemy. During the winter break, I devoted a significant amount of time to studying and reflecting on these topics. I started from a point where I had very limited knowledge of coding and AI, and gradually worked my way toward being able to complete these assignments. This process required substantial effort and persistence. Honestly, AI played a crucial role in supporting my learning and problem-solving throughout this journey. Honestly, I do not yet fully understand every detail at a deep level, with the help of AI and additional reading, but I was able to grasp the core principles and working mechanisms of the methods involved. I will continue to study independently and improve my understanding, as I believe continuous learning is an essential quality for a scientist.
## (1.3) Hartree–Fock
This was the first task I worked on after learning the basic concepts of computational chemistry, such as potential energy surfaces (PES), zero-point vibrational energy (ZPVE), the variational method, and the Hartree–Fock approach. I began implementing this code after completing my study of the Hartree–Fock method and used AI as a tool to help organize information and derive the necessary mathematical formulations for Gaussian basis functions.
By implementing the restricted Hartree–Fock method from scratch, I gained a concrete understanding of the self-consistent field (SCF) procedure, including the construction of the Fock matrix, the density matrix, and the role of electron–electron interactions through Coulomb and exchange terms. I learned that Hartree–Fock provides a reasonable description of the electronic energy for small systems such as H₂ and HeH⁺. For larger systems like LiH, the complexity increases significantly, so I chose H₂ and HeH⁺ as test systems to keep the implementation as simple as possible.I spent more than three days developing ideas, consulting AI for guidance, writing code, debugging, and optimizing my implementation. After completing the calculation, I compared my results with values reported in the literature and obtained relative errors of approximately 4.9% for H₂ and 4.0% for HeH⁺, which I consider acceptable given the use of a minimal basis set.
## (1.6) Metropolis–Hastings
I started working on this part while studying probability theory, statistics, and machine learning. I began with fundamental statistical concepts such as Bayes’ theorem and then moved on to rejection sampling, Gibbs sampling, and the Metropolis–Hastings algorithm. Through this exercise, I learned that the burn-in phase is essential, as early samples depend strongly on the initial conditions. Discarding these initial samples helps ensure that the remaining data better represents the target distribution.
## (1.7) Path Integral Monte Carlo
Through this task, I recognized the close relationship between Metropolis–Hastings and Monte Carlo methods. Metropolis–Hastings is a specific approach for performing Monte Carlo sampling when direct random sampling from the target distribution is not possible. Instead of generating independent samples, the algorithm produces a sequence of samples in which each new sample depends only on the current one and is accepted with a certain probability.

